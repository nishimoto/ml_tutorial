{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習の精度を上げる（パラメーターチューニング）\n",
    "\n",
    "## 目次\n",
    "\n",
    " - ハイパーパラメーターとは？\n",
    " - グリッドサーチによるパラメーターサーチ\n",
    " - ベイズ最適化によるパラメーターサーチ\n",
    " - スタッキングによる精度向上\n",
    "\n",
    "## ハイパーパラメーターとは?\n",
    "\n",
    "「機械学習アルゴリズムにおいて、人が調整するべきパラメーターのこと」です。\n",
    "\n",
    "例えば、ディープラーニングにおける、層の数などがパラメーターに相当します。\n",
    "\n",
    "<img src=\"./assets/pic/deeplearning1.png\" width=\"50%\">\n",
    "\n",
    "今回は、2種類の手法でハイパーパラメータを探索します。\n",
    "\n",
    "①：グリッドサーチ（いくつかの値の全組み合わせを試し、最適な値を探す）\n",
    "\n",
    "②：ベイズ最適化によるパラメーターサーチ\n",
    "\n",
    "②の方が使用されていることは多いですが、両方試してみます。\n",
    "\n",
    "## 探索範囲について\n",
    "\n",
    "私が使用しているパラメーター探索範囲は以下です。[公式のリファレンス](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier)も参照ください。\n",
    "\n",
    "```python\n",
    "all_params = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'min_child_weight': [3, 5, 10],\n",
    "    'n_estimetors': [10000],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'colsample_bylevel': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'random_state': [0],\n",
    "    'n_jobs': [1],\n",
    "}\n",
    "```\n",
    "\n",
    "## グリッドサーチによるパラメーターサーチ\n",
    "\n",
    "(`sklearn.model_selection.ParameterGrid`)[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html] に上記の辞書を与えると、全通りのパラメーターを作ってくれます。\n",
    "\n",
    "以下は検証用のミニコード。\n",
    "\n",
    " - ソースコード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bylevel': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimetors': 10000, 'n_jobs': 1, 'random_state': 0, 'reg_alpha': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "all_params = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'min_child_weight': [3, 5, 10],\n",
    "    'n_estimetors': [10000],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'colsample_bylevel': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'random_state': [0],\n",
    "    'n_jobs': [1],\n",
    "}\n",
    "\n",
    "for params in ParameterGrid(all_params):\n",
    "    print(params)\n",
    "    break # ここコメントアウトすると全部のパラメーターが出力されていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際のソースコードで試してみます。\n",
    "\n",
    " - ソースコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3d327d9ae44e7f897ad539602bf6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=324), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8395061728395062 {'colsample_bylevel': 0.9, 'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 5, 'n_estimetors': 10000, 'n_jobs': 1, 'random_state': 0, 'reg_alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 組み合わせが多いので、進捗を可視化するツールを入れました。\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# all_paramsはグローバル変数として宣言\n",
    "all_params = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'min_child_weight': [3, 5, 10],\n",
    "    'n_estimetors': [10000],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'colsample_bylevel': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'random_state': [0],\n",
    "    'n_jobs': [1],\n",
    "}\n",
    "\n",
    "\n",
    "def validate(train_x, train_y, params):\n",
    "    accuracies = []\n",
    "    feature_importances = []\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "    for train_idx, test_idx in cv.split(train_x, train_y):\n",
    "        trn_x = train_x.iloc[train_idx, :]\n",
    "        val_x = train_x.iloc[test_idx, :]\n",
    "\n",
    "        trn_y = train_y.iloc[train_idx]\n",
    "        val_y = train_y.iloc[test_idx]\n",
    "\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "        clf.fit(trn_x, trn_y)\n",
    "\n",
    "        pred_y = clf.predict(val_x)\n",
    "        feature_importances.append(clf.feature_importances_)\n",
    "        accuracies.append(accuracy_score(val_y, pred_y))\n",
    "    print(np.mean(accuracies))\n",
    "    return accuracies, feature_importances\n",
    "\n",
    "\n",
    "def plot_feature_importances(feature_importances, cols):\n",
    "    df_fimp = pd.DataFrame(feature_importances, columns=cols)\n",
    "    df_fimp.plot(kind=\"box\", rot=90)\n",
    "\n",
    "\n",
    "def preprocess_df(df):\n",
    "    # CabinはこのあとDropするので、コードから削除\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode())\n",
    "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "   \n",
    "    # 列の削除\n",
    "    df.drop([\"Name\", \"Ticket\", \"Cabin\", \"PassengerId\"], axis=1, inplace=True)\n",
    "\n",
    "    # Sexの01化とEmbarkedのダミー化 \n",
    "    df[\"Sex\"] = df[\"Sex\"].replace({\"male\": 0, \"female\": 1})\n",
    "    df = pd.get_dummies(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# test dataのpredict\n",
    "def predict_df(train_x, train_y, test_x, df_test_raw, path_output=\"result.csv\"):\n",
    "    params = {'learning_rate': 0.008306052798923729, 'max_depth': 7, 'min_child_weight': 3, 'colsample_bytree': 0.8210307463506532, 'colsample_bylevel': 0.8061816543590015}\n",
    "    clf = xgb.XGBClassifier(**params)\n",
    "    clf.fit(train_x, train_y)\n",
    "    preds = clf.predict(test_x)\n",
    "    \n",
    "    _df = pd.DataFrame()\n",
    "    _df[\"PassengerId\"] = df_test_raw[\"PassengerId\"]\n",
    "    _df[\"Survived\"] = preds\n",
    "    _df.to_csv(path_output, index=False)\n",
    "\n",
    "\n",
    "def main():\n",
    "    df_train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "    # ここは前処理\n",
    "    train_y = df_train[\"Survived\"]\n",
    "    train_x = df_train.drop(\"Survived\", axis=1)\n",
    "\n",
    "    train_x = preprocess_df(train_x)\n",
    "    accuracies, feature_importances = validate(train_x, train_y, {})\n",
    "    print(np.mean(accuracies))\n",
    "    plot_feature_importances(feature_importances, train_x.columns)\n",
    "\n",
    "    flag_product = True\n",
    "    if flag_product:\n",
    "        df_test = pd.read_csv(\"test.csv\")\n",
    "        df_test_raw = df_test.copy()\n",
    "        test_x = preprocess_df(df_test)\n",
    "        predict_df(train_x, train_y, test_x, df_test_raw, \"result.csv\")\n",
    "\n",
    "# main文を書き換えているので、別関数として定義\n",
    "def main_parametersearch():\n",
    "    df_train = pd.read_csv(\"train.csv\")\n",
    "    train_y = df_train[\"Survived\"]\n",
    "    train_x = df_train.drop(\"Survived\", axis=1)\n",
    "    train_x = preprocess_df(train_x)\n",
    "\n",
    "    # ここまではmainと同じ\n",
    "    # tqdmで囲むことで、進捗を可視化できます。\n",
    "    best_score = 0\n",
    "    best_params = {}\n",
    "    for params in tqdm(ParameterGrid(all_params)):\n",
    "        accuracies, feature_importances = validate(train_x, train_y, params)\n",
    "        \n",
    "        # もしaccuracyの平均値が最大だった場合、\n",
    "        # best_scoreを更新して、best_paramsを更新する。\n",
    "        if np.mean(accuracies) > best_score:\n",
    "            best_score = np.mean(accuracies)\n",
    "            best_params = params\n",
    "    print(best_score, best_params)\n",
    "\n",
    "# 呼んでいる関数を変えた\n",
    "if __name__ == '__main__':\n",
    "    main_parametersearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元々のaccuracyより0.01ほど精度が上がっているのがわかると思います。\n",
    "\n",
    "次に、ベイズ最適化によるパラメーターサーチを試してみます。\n",
    "\n",
    "## ベイズ最適化によるパラメーターサーチ\n",
    "\n",
    "ベイズ最適化はハイパーパラメーターをより効率的に探してくれるためのアルゴリズムです。\n",
    "\n",
    "原理については[明治大の金子先生のページ](https://datachemeng.com/bayesianoptimization/)がわかりやすいです。\n",
    "\n",
    "イメージとしては、 \n",
    "\n",
    "①：よい精度を出したところを深く探索する\n",
    "\n",
    "②：たまにハイパーパラメーターを全く変えて、もっと深いところがないか探索する\n",
    "\n",
    "の2つを組み合わせることで最適なパラメーターを探索しています。\n",
    "\n",
    "ここでは[PFNの人が作られたOptunaというライブラリー](https://optuna.org/)を使用します。\n",
    "\n",
    " -  ソースコード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17059483726150404\n",
      "{'learning_rate': 0.008306052798923729, 'max_depth': 7, 'min_child_weight': 3, 'colsample_bytree': 0.8210307463506532, 'colsample_bylevel': 0.8061816543590015}\n"
     ]
    }
   ],
   "source": [
    "# !pip install optuna # ライブラリーのインストールコマンド\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# optunaの出力をsupressする\n",
    "# https://optuna.readthedocs.io/en/stable/faq.html#how-to-suppress-log-messages-of-optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'seed': 0,\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-2),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 3, 10),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.8, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_loguniform('colsample_bylevel', 0.8, 1.0),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "    accuracies = []\n",
    "    for train_idx, test_idx in cv.split(train_x, train_y):\n",
    "        trn_x = train_x.iloc[train_idx, :]\n",
    "        val_x = train_x.iloc[test_idx, :]\n",
    "\n",
    "        trn_y = train_y.iloc[train_idx]\n",
    "        val_y = train_y.iloc[test_idx]\n",
    "\n",
    "        # main - Predict\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "        clf.fit(trn_x, trn_y)\n",
    "\n",
    "        pred_y = clf.predict(val_x)\n",
    "        accuracies.append(accuracy_score(val_y, pred_y))\n",
    "\n",
    "    return 1.0 - np.mean(accuracies)\n",
    "\n",
    "\n",
    "def preprocess_df(df):\n",
    "    # CabinはこのあとDropするので、コードから削除\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode())\n",
    "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "   \n",
    "    # 列の削除\n",
    "    df.drop([\"Name\", \"Ticket\", \"Cabin\", \"PassengerId\"], axis=1, inplace=True)\n",
    "\n",
    "    # Sexの01化とEmbarkedのダミー化 \n",
    "    df[\"Sex\"] = df[\"Sex\"].replace({\"male\": 0, \"female\": 1})\n",
    "    df = pd.get_dummies(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# main\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "train_y = df_train[\"Survived\"]\n",
    "train_x = df_train.drop(\"Survived\", axis=1)\n",
    "train_x = preprocess_df(train_x)\n",
    "\n",
    "# random_stateを固定する\n",
    "# 実際は要らないですが、今回はチュートリアルなので導入しています。\n",
    "# https://optuna.readthedocs.io/en/stable/faq.html#how-can-i-obtain-reproducible-optimization-results\n",
    "sampler = optuna.samplers.TPESampler(seed=100) # Make the sampler behave in a deterministic way.\n",
    "study = optuna.create_study(sampler=sampler)\n",
    "study.optimize(objective, n_trials=100, n_jobs=1)\n",
    "print(study.best_trial.value)\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optunaは使い方が少し特殊です。\n",
    "\n",
    "基本的には\n",
    "\n",
    "①：精度を返す関数を作る （`objective`関数）\n",
    "\n",
    "②：その関数をOptunaに投げる　（`study.optimize`の引数に取る）\n",
    " \n",
    "の2工程で対応できます。\n",
    "\n",
    "詳細はソースコード + コメントをご参照ください。\n",
    "\n",
    "最後に、実際にtest.csvも予測してみます。\n",
    "\n",
    " - ソースコード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.829405162738496\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = study.best_trial.params\n",
    "\n",
    "def main():\n",
    "    df_train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "    train_y = df_train[\"Survived\"]\n",
    "    train_x = df_train.drop(\"Survived\", axis=1)\n",
    "\n",
    "    train_x = preprocess_df(train_x)\n",
    "    accuracies, feature_importances = validate(train_x, train_y, params) # paramsに書き換えました。\n",
    "    print(np.mean(accuracies))\n",
    "    plot_feature_importances(feature_importances, train_x.columns)\n",
    "\n",
    "    flag_product = True\n",
    "    if flag_product:\n",
    "        df_test = pd.read_csv(\"test.csv\")\n",
    "        df_test_raw = df_test.copy()\n",
    "        test_x = preprocess_df(df_test)\n",
    "        predict_df(train_x, train_y, test_x, df_test_raw, \"result.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OptunaでチューニングしたパラメーターをKaggleへSubmitすると、精度が0.78468になればOKです。\n",
    "\n",
    "## アンサンブルによる精度向上\n",
    "\n",
    "機械学習において、**単一のモデルをそのまま使うのではなく、複数のモデルを組み合わせることで、精度を上げる**手法をアンサンブル学習といいます。\n",
    "\n",
    "実際のKaggleではアンサンブルによる精度向上がかなり大きく、これだけである程度の順位を取ることができます。\n",
    "\n",
    "ここでは、機械学習のアルゴリズムを2つ組み合わせて（LightGBMとXGBoost）、精度がよくなるかを見てみます。\n",
    "\n",
    " - ソースコード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8215488215488215\n"
     ]
    }
   ],
   "source": [
    "# 今回はクロスバリデーションで精度を出す以外のところは削っています。\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# main文\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "train_y = df_train[\"Survived\"]\n",
    "train_x = df_train.drop(\"Survived\", axis=1)\n",
    "\n",
    "train_x = preprocess_df(train_x)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "for train_idx, test_idx in cv.split(train_x, train_y):\n",
    "    trn_x = train_x.iloc[train_idx, :]\n",
    "    val_x = train_x.iloc[test_idx, :]\n",
    "\n",
    "    trn_y = train_y.iloc[train_idx]\n",
    "    val_y = train_y.iloc[test_idx]\n",
    "\n",
    "    clf_xgb = xgb.XGBClassifier(**params)\n",
    "    clf_lgb = lgb.LGBMClassifier(**params)\n",
    "\n",
    "    clf_xgb.fit(trn_x, trn_y)\n",
    "    clf_lgb.fit(trn_x, trn_y)\n",
    "    \n",
    "    # 平均値化するためにprobabilityを出した\n",
    "    pred_proba_y_xgb = clf_xgb.predict_proba(val_x)[:, 1]\n",
    "    pred_proba_y_lgb = clf_lgb.predict_proba(val_x)[:, 1]\n",
    "    \n",
    "    # probabilityの平均値が0.50を超えていれば1, そうでないなら0\n",
    "    pred_proba_y = pd.DataFrame({\"xgb\": pred_proba_y_xgb, \"lgb\": pred_proba_y_lgb}).mean(axis=1)\n",
    "    pred_y = [1 if proba > 0.50 else 0 for proba in pred_proba_y]\n",
    "    accuracies.append(accuracy_score(val_y, pred_y))\n",
    "\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "今回は精度は下がってしまいました。。\n",
    "\n",
    "今回は単純に平均値を取っただけですが、実際は複数の判別モデルから出力された値をさらに機械学習に入れ込むStackingなど、\n",
    "\n",
    "様々な手法が取られています。\n",
    "\n",
    "## おわりに\n",
    "\n",
    "機械学習において、特徴量エンジニアリングの方がハイパーパラメーター探索より重要であることが多いです。\n",
    "\n",
    "ただ、ハイパーパラメーターのチューニングも必要な技術ではあるので、一通りおさらいしました。\n",
    "\n",
    "ここで概ね機械学習の講座は終わりです。 最後の８章で今後の方針を示します。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
